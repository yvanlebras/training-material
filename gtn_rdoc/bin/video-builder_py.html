<!DOCTYPE html>

<html>
<head>
<meta charset="UTF-8">

<title>video-builder.py - RDoc Documentation</title>

<script type="text/javascript">
  var rdoc_rel_prefix = "../";
  var index_rel_prefix = "../";
</script>

<script src="../js/navigation.js" defer></script>
<script src="../js/search.js" defer></script>
<script src="../js/search_index.js" defer></script>
<script src="../js/searcher.js" defer></script>
<script src="../js/darkfish.js" defer></script>

<link href="../css/fonts.css" rel="stylesheet">
<link href="../css/rdoc.css" rel="stylesheet">


<body id="top" role="document" class="file">
<nav role="navigation">
  <div id="project-navigation">
    <div id="home-section" role="region" title="Quick navigation" class="nav-section">
  <h2>
    <a href="../index.html" rel="home">Home</a>
  </h2>

  <div id="table-of-contents-navigation">
    <a href="../table_of_contents.html#pages">Pages</a>
    <a href="../table_of_contents.html#classes">Classes</a>
    <a href="../table_of_contents.html#methods">Methods</a>
  </div>
</div>

    <div id="search-section" role="search" class="project-section initially-hidden">
  <form action="#" method="get" accept-charset="utf-8">
    <div id="search-field-wrapper">
      <input id="search-field" role="combobox" aria-label="Search"
             aria-autocomplete="list" aria-controls="search-results"
             type="text" name="search" placeholder="Search" spellcheck="false"
             title="Type to search, Up and Down to navigate, Enter to load">
    </div>

    <ul id="search-results" aria-label="Search Results"
        aria-busy="false" aria-expanded="false"
        aria-atomic="false" class="initially-hidden"></ul>
  </form>
</div>

  </div>

  

  <div id="project-metadata">
    
<div id="fileindex-section" class="nav-section">
  <h3>Pages</h3>

  <ul class="link-list">
    <li><a href="../bin/add_galaxy_instance_badges_py.html">add_galaxy_instance_badges.py</a>
    <li><a href="../bin/ari-gen-sample-audio_sh.html">ari-gen-sample-audio.sh</a>
    <li><a href="../bin/ari-make_sh.html">ari-make.sh</a>
    <li><a href="../bin/ari-quick_sh.html">ari-quick.sh</a>
    <li><a href="../bin/ari_sh.html">ari.sh</a>
    <li><a href="../bin/check-broken-boxes_py.html">check-broken-boxes.py</a>
    <li><a href="../bin/data-library-update_sh.html">data-library-update.sh</a>
    <li><a href="../bin/data_libarary_download_sh.html">data_libarary_download.sh</a>
    <li><a href="../bin/docker-install-tutorials_sh.html">docker-install-tutorials.sh</a>
    <li><a href="../bin/gtn-fix_sh.html">gtn-fix.sh</a>
    <li><a href="../bin/install_topic_requirements_sh.html">install_topic_requirements.sh</a>
    <li><a href="../bin/install_tutorial_requirements_sh.html">install_tutorial_requirements.sh</a>
    <li><a href="../bin/knit-automated_sh.html">knit-automated.sh</a>
    <li><a href="../bin/knit-frog_py.html">knit-frog.py</a>
    <li><a href="../bin/knit_py.html">knit.py</a>
    <li><a href="../bin/knittingneedles_py.html">knittingneedles.py</a>
    <li><a href="../bin/lint-diffs_py.html">lint-diffs.py</a>
    <li><a href="../bin/lunr-index_js.html">lunr-index.js</a>
    <li><a href="../bin/lunr-search_js.html">lunr-search.js</a>
    <li><a href="../bin/mergeyaml_py.html">mergeyaml.py</a>
    <li><a href="../bin/prepare_docker_checks_py.html">prepare_docker_checks.py</a>
    <li><a href="../bin/publish-archive.html">publish-archive</a>
    <li><a href="../bin/schema-contributors_yaml.html">schema-contributors.yaml</a>
    <li><a href="../bin/schema-faq_yaml.html">schema-faq.yaml</a>
    <li><a href="../bin/schema-learning-pathway_yaml.html">schema-learning-pathway.yaml</a>
    <li><a href="../bin/schema-news_yaml.html">schema-news.yaml</a>
    <li><a href="../bin/schema-quiz_yaml.html">schema-quiz.yaml</a>
    <li><a href="../bin/schema-requirement-external_yaml.html">schema-requirement-external.yaml</a>
    <li><a href="../bin/schema-requirement-internal_yaml.html">schema-requirement-internal.yaml</a>
    <li><a href="../bin/schema-slides_yaml.html">schema-slides.yaml</a>
    <li><a href="../bin/schema-topic_yaml.html">schema-topic.yaml</a>
    <li><a href="../bin/schema-tutorial_yaml.html">schema-tutorial.yaml</a>
    <li><a href="../bin/setup_training_content_py.html">setup_training_content.py</a>
    <li><a href="../bin/slides-fix_css.html">slides-fix.css</a>
    <li><a href="../bin/supported-fetch_py.html">supported-fetch.py</a>
    <li><a href="../bin/validate-has-workflow_sh.html">validate-has-workflow.sh</a>
    <li><a href="../bin/video-browser-recorder_js.html">video-browser-recorder.js</a>
    <li><a href="../bin/video-builder_py.html">video-builder.py</a>
    <li><a href="../bin/video-diffplayer_py.html">video-diffplayer.py</a>
    <li><a href="../bin/video-extract-script_py.html">video-extract-script.py</a>
    <li><a href="../bin/video-term-demo-magic_sh.html">video-term-demo-magic.sh</a>
    <li><a href="../bin/video-term-recorder_sh.html">video-term-recorder.sh</a>
    <li><a href="../bin/yaml2json_py.html">yaml2json.py</a>
  </ul>
</div>

  </div>
</nav>

<main role="main" aria-label="Page bin/video-builder.py">

<p>#!/usr/bin/env python import os import re import subprocess import tempfile import json import yaml import sys</p>

<p>GTN_HOME = os.path.join(os.path.dirname(os.path.realpath(__file__)), “..”)</p>

<p>ANSIBLE_HOST_OVERRIDE = “gat-1.be.training.galaxyproject.eu” GTN_URL = “<a href="https://training.galaxyproject.org/training-material">training.galaxyproject.org/training-material</a>” GXY_URL = “<a href="https://gat-1.be.training.galaxyproject.eu">gat-1.be.training.galaxyproject.eu</a>” GIT_GAT = &#39;/home/ubuntu/galaxy/&#39;</p>

<p>GTN_URL = “<a href="http://localhost:4002/training-material">localhost:4002/training-material</a>” GIT_GAT = &#39;/home/hxr/arbeit/galaxy/git-gat&#39;</p>

<p>data = <a href="1">yaml.safe_load(open(sys.argv</a>, “r”).read()) meta = <a href=""meta"">data</a> steps = <a href=""steps"">data</a></p>

<p>import os</p>

<p>if os.path.exists(“.step.cache.json”):</p>

<pre>with open(&quot;.step.cache.json&quot;, &quot;r&quot;) as handle:
    steps = json.load(handle)</pre>

<p># First pass, we&#39;ll record all of the audio, and nothing else. for step in steps:</p>

<pre># Ignore cached data
if &quot;mediameta&quot; in step:
    continue

# Need to record
if &quot;text&quot; in step:
    tmp = tempfile.NamedTemporaryFile(mode=&quot;w&quot;, delete=False)
    tmp.write(step[&quot;text&quot;])
    tmp.close()

    cmd = [
        &quot;ruby&quot;,
        &quot;bin/ari-synthesize.rb&quot;,
        &quot;--aws&quot;,
        &quot;-f&quot;,
        tmp.name,
        &quot;--voice=&quot; + meta[&quot;voice&quot;][&quot;id&quot;],
        &quot;--lang=&quot; + meta[&quot;voice&quot;][&quot;lang&quot;],
    ]
    if not meta[&quot;voice&quot;][&quot;neural&quot;]:
        cmd.append(&quot;--non-neural&quot;)

    # Create the mp3
    mp3 = subprocess.check_output(cmd).decode(&quot;utf-8&quot;).strip()
    # And remove our temp file
    try:
        os.unlink(tmp)
    except:
        pass

    print(mp3)
    with open(mp3.replace(&quot;.mp3&quot;, &quot;.json&quot;), &quot;r&quot;) as handle:
        mediameta = json.load(handle)
        del mediameta[&quot;value&quot;]
    step[&quot;mediameta&quot;] = mediameta
    step[&quot;mediameta&quot;][&quot;fn&quot;] = mp3

if &quot;visual&quot; not in step[&quot;data&quot;]:
    raise Exception(&quot;Hey, missing a visual, we can&#39;t process this script.&quot;)

with open(&quot;.step.cache.json&quot;, &quot;w&quot;) as handle:
    json.dump(steps, handle)</pre>

<p>def loadGitGatCommits(tutorial=“admin/cvmfs”):</p>

<pre>subprocess.check_call([&quot;git&quot;, &quot;stash&quot;], cwd=GIT_GAT)
subprocess.check_call([&quot;git&quot;, &quot;checkout&quot;, &quot;main&quot;], cwd=GIT_GAT)
results = subprocess.check_output([&quot;git&quot;, &quot;log&quot;, &quot;--pretty=reference&quot;], cwd=GIT_GAT).decode(&quot;utf-8&quot;)
commits = results.strip().split(&quot;\n&quot;)[::-1]
commits = [x for x in commits if tutorial in x]
commitMap = {}
for commit in commits:
    m = re.match(&quot;([0-9a-f]+) \(.*: (.*), [0-9-]*\)&quot;, commit)
    g = m.groups()
    commitMap[g[1]] = g[0]
return commitMap</pre>

<p>commitMap = loadGitGatCommits()</p>

<p>def runningGroup(steps):</p>

<pre>c = None
for step in steps:
    if c is None:
        c = [step]
        continue

    # If the new visual is different, then
    if step[&quot;data&quot;][&quot;visual&quot;] != c[-1][&quot;data&quot;][&quot;visual&quot;]:
        # Yield the current list
        yield c
        # And reset it with current step
        c = [step]
    else:
        c.append(step)
yield c</pre>

<p>def calculateSyncing(syncpoints, audio):</p>

<pre>&quot;&quot;&quot;
# This tracks where in the video precisely (mostly) the audio should start
syncpoints = [
    {&quot;msg&quot;: &quot;checkout&quot;, &quot;time&quot;: 162.959351},
    {&quot;msg&quot;: &quot;cmd&quot;, &quot;time&quot;: 18899.63733},
    {&quot;msg&quot;: &quot;cmd&quot;, &quot;time&quot;: 22978.593038},
]

# Here are the lengths of the audio
audio = [
    {&quot;end&quot;: 13.608},
    {&quot;end&quot;: 3.936},
    {&quot;end&quot;: 7.488},
]

So we need to get back something that has like (the commnd took 18.89
seconds to run, but we have 13 seconds of audio, the next clip needs a 5
second delay)

{&#39;end&#39;: 13.608} 162.959
{&#39;end&#39;: 3.936} 5128.677
{&#39;end&#39;: 7.488}  142.955
&quot;&quot;&quot;
if len(syncpoints) != len(audio):
    print(&quot;????? Something odd is going on!&quot;)

since = 0
for (aud, syn) in zip(audio, syncpoints):
    delay = syn[&quot;time&quot;] - since
    yield (int(delay), aud)
    since = syn[&quot;time&quot;] + (aud[&quot;mediameta&quot;][&quot;end&quot;] * 1000)</pre>

<p>def muxAudioVideo(group, videoin, videoout, syncpoints):</p>

<pre># We&#39;ll construct a complex ffmpeg filter here.
#
# There is incorrect quotation/line breaking in the filter_complex for clarity
# ffmpeg -i video.mp4 \
#   -i test3.mp3 \
#   -i test3.mp3 \
#   -filter_complex \
#     &quot;[1:a]atrim=start=0,adelay=500,asetpts=PTS-STARTPTS[a1];
#      [2:a]atrim=start=0,adelay=20,asetpts=PTS-STARTPTS[a2];
#      [a1][a2]concat=n=2:v=0:a=1[a]&quot; \
# -map 0:v -map &quot;[a]&quot; -y output.mp4
#
# We start by inputting all media (video, N audio samples)
# Then we run a filter complex.
# For each audio sample:
#    we need to list it in the complex filter. We number then [1:a]... and refer to them as [a1]...
#      atrim=start=0 to use the entire audio sample every time
#                    http://ffmpeg.org/ffmpeg-filters.html#atrim
#      adelay=500    value in miliseconds, we want to offset the first
#                    clip relative to video start, the rest are offset
#                    relative to each other (which in practice is a
#                    negligible amount.)
#                    http://ffmpeg.org/ffmpeg-filters.html#adelay
#      asetpts=PTS-STARTPTS[..]
#                    This is some magic I copied from SO. I don&#39;t super
#                    get what it does, something about fixing
#                    timestamps so there&#39;s no jitter in audio.
#                    http://ffmpeg.org/ffmpeg-filters.html#asetpts
# Then we list all audios with a concat filter and the number of samples.
# [a1][a2]concat=n=2:v=0:a=1[a]
# I read this as [audio1][audio2] concatentate filter with n=2samples : v(ideo)=off, a(udio)=on from [a] array of audio.
# it works?
#  and lastly we map things together into our output file.
mux_cmd = [&quot;ffmpeg&quot;, &quot;-i&quot;, videoin]
for g in group:
    mux_cmd.extend([&quot;-i&quot;, g[&quot;mediameta&quot;][&quot;fn&quot;]])
mux_cmd.append(&quot;-filter_complex&quot;)

delayResults = list(calculateSyncing(syncpoints, group))

# The first audio sample must have a correct adelay for when that action happens.
complex_filter = []
concat_filter = &quot;&quot;
for i2, (delay, g) in enumerate(delayResults, start=1):
    filt = f&quot;[{i2}:a]atrim=start=0,adelay={delay},asetpts=PTS-STARTPTS[a{i2}]&quot;
    print(filt)
    complex_filter.append(filt)
    concat_filter += f&quot;[a{i2}]&quot;

final_concat = f&quot;{concat_filter}concat=n={len(group)}:v=0:a=1[a]&quot;
complex_filter.append(final_concat)
final_complex = &quot;;&quot;.join(complex_filter)
mux_cmd.extend([final_complex, &quot;-map&quot;, &quot;0:v&quot;, &quot;-map&quot;, &quot;[a]&quot;, videoout])
# print(&quot; &quot;.join(mux_cmd))
subprocess.check_call(mux_cmd)</pre>

<p>def recordBrowser(idx):</p>

<pre># Record our video. It&#39;ll start with a blank screen and page loading which we&#39;ll need to crop.
if os.path.exists(f&quot;video-{idx}.mp4&quot;):
    return

silent_video = f&quot;video-{idx}-silent.mp4&quot;
silent_video_cropped = f&quot;video-{idx}-cropped.mp4&quot;
cmd = [
    &quot;/srv/galaxy/venv/bin/node&quot;,
    os.path.join(GTN_HOME, &quot;bin&quot;, &quot;video-browser-recorder.js&quot;),
    f&quot;scene-{idx}.json&quot;,
    silent_video,
]
print(&quot; &quot;.join(cmd))
resulting_script = json.loads(subprocess.check_output(cmd).decode(&quot;utf-8&quot;))

# Get the amount of time before the first scrollTo
adelay = resulting_script[0][&quot;time&quot;]

# Crop the &#39;init&#39; portion of the video.
cmd = [
    &quot;ffmpeg&quot;,
    &quot;-ss&quot;,
    f&quot;{adelay}ms&quot;,
    &quot;-i&quot;,
    silent_video,
    &quot;-c&quot;,
    &quot;copy&quot;,
    silent_video_cropped,
]
print(&quot; &quot;.join(cmd))
subprocess.check_call(cmd)

# Build the video with sound.
muxAudioVideo(group, silent_video_cropped, f&quot;video-{idx}.mp4&quot;, resulting_script[1:])</pre>

<p>def recordGtn(idx, group):</p>

<pre># We&#39;ve got N bits of text
actions = [{&quot;action&quot;: &quot;goto&quot;, &quot;target&quot;: GTN_URL + &quot;/topics/admin/tutorials/cvmfs/tutorial.html&quot;}]
for g in group:
    actions.append(
        {&quot;action&quot;: &quot;scrollTo&quot;, &quot;target&quot;: g[&quot;data&quot;][&quot;target&quot;], &quot;sleep&quot;: g[&quot;mediameta&quot;][&quot;end&quot;],}
    )

with open(f&quot;scene-{idx}.json&quot;, &quot;w&quot;) as handle:
    json.dump(actions, handle)

recordBrowser(idx)</pre>

<p>def recordGxy(idx, group):</p>

<pre>actions = [{&quot;action&quot;: &quot;goto&quot;, &quot;target&quot;: GXY_URL,}]
for g in group:
    action = {
        &quot;action&quot;: g[&quot;data&quot;][&quot;action&quot;],
        &quot;target&quot;: g[&quot;data&quot;][&quot;target&quot;],
        &quot;value&quot;: g[&quot;data&quot;].get(&quot;value&quot;, None),
        &quot;sleep&quot;: g[&quot;mediameta&quot;][&quot;end&quot;],
    }
    if action[&quot;action&quot;] == &quot;goto&quot;:
        action[&quot;target&quot;] = GXY_URL + action[&quot;target&quot;]

    actions.append(action)

with open(f&quot;scene-{idx}.json&quot;, &quot;w&quot;) as handle:
    json.dump(actions, handle)

recordBrowser(idx)</pre>

<p>def recordTerm(idx, group):</p>

<pre>if os.path.exists(f&quot;video-{idx}.mp4&quot;):
    return

actions = []
for g in group:
    if &quot;commit&quot; in g[&quot;data&quot;]:
        g[&quot;data&quot;][&quot;commitId&quot;] = commitMap[g[&quot;data&quot;][&quot;commit&quot;]]
        del g[&quot;code&quot;]

    # t = g.get(&#39;mediameta&#39;, {&#39;end&#39;: -1})[&#39;end&#39;]
    t = g[&quot;mediameta&quot;][&quot;end&quot;]
    if &quot;commitId&quot; in g[&quot;data&quot;]:
        actions.append({&quot;action&quot;: &quot;checkout&quot;, &quot;time&quot;: t, &quot;data&quot;: g[&quot;data&quot;][&quot;commitId&quot;]})
    else:
        if &quot;cmd&quot; in g:
            cmd = g[&quot;cmd&quot;]
        elif &quot;cmd&quot; in g[&quot;data&quot;]:
            cmd = g[&quot;data&quot;][&quot;cmd&quot;]
        else:
            print(&quot;????? SOMETHING IS WRONG&quot;)
        actions.append({&quot;action&quot;: &quot;cmd&quot;, &quot;time&quot;: t, &quot;data&quot;: cmd})
with open(f&quot;scene-{idx}.json&quot;, &quot;w&quot;) as handle:
    json.dump(actions, handle)

# Remove any previous versions of the cast.
cast_file = f&quot;{GTN_HOME}/scene-{idx}.cast&quot;
if os.path.exists(cast_file):
    os.unlink(cast_file)

# Do the recording
innercmd = [
    &quot;bash&quot;,
    os.path.join(GTN_HOME, &quot;bin&quot;, &quot;video-term-recorder.sh&quot;),
    f&quot;{GTN_HOME}/scene-{idx}.json&quot;,
    f&quot;{GTN_HOME}/scene-{idx}.log&quot;,
    ANSIBLE_HOST_OVERRIDE,
    GIT_GAT,
]
cmd = [
    &quot;asciinema&quot;,
    &quot;rec&quot;,
    cast_file,
    &quot;-t&quot;,
    f&quot;Scene {idx}&quot;,
    &quot;-c&quot;,
    &quot; &quot;.join(innercmd),
]
print(&#39; &#39;.join(cmd))
subprocess.check_call(cmd)
# Convert to MP4
subprocess.check_call(
    [&quot;python&quot;, &quot;asciicast2movie/asciicast2movie.py&quot;, f&quot;scene-{idx}.cast&quot;, f&quot;scene-{idx}.mp4&quot;,]
)

resulting_script = []
with open(f&quot;scene-{idx}.log&quot;, &quot;r&quot;) as handle:
    for line in handle.readlines():
        line = line.strip().split(&quot;\t&quot;)
        resulting_script.append(
            {&quot;time&quot;: float(line[0]) * 1000, &quot;msg&quot;: line[1],}
        )

# Mux with audio
muxAudioVideo(group, f&quot;scene-{idx}.mp4&quot;, f&quot;video-{idx}.mp4&quot;, resulting_script)</pre>

<p># Next pass, we&#39;ll aggregate things of the same &#39;type&#39;. This will make # recording videos easier because we can more smoothly tween between steps. # E.g. scrolling in GTN + waiting.  Or recording N things in the terminal and # the audios for those. for idx, group in enumerate(runningGroup(steps)):</p>

<pre>typ = group[0][&quot;data&quot;][&quot;visual&quot;]
# print(typ, len(group), idx)
if typ == &quot;gtn&quot;:
    recordGtn(idx, group)
elif typ == &quot;terminal&quot;:
    recordTerm(idx, group)
elif typ == &quot;galaxy&quot;:
    recordGxy(idx, group)</pre>

</main>



<footer id="validator-badges" role="contentinfo">
  <p><a href="https://validator.w3.org/check/referer">Validate</a>
  <p>Generated by <a href="https://ruby.github.io/rdoc/">RDoc</a> 6.3.3.
  <p>Based on <a href="http://deveiate.org/projects/Darkfish-RDoc/">Darkfish</a> by <a href="http://deveiate.org">Michael Granger</a>.
</footer>

